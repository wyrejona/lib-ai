from fastapi import FastAPI, Request, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from pathlib import Path
import logging
import sys
import os
import shutil
from datetime import datetime

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize FastAPI
app = FastAPI(
    title="Library Support AI",
    version="1.0.0",
    description="University of Embu Library Support AI"
)

# Add middleware
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Get base directory
BASE_DIR = Path(__file__).parent.parent

# Setup templates directory
templates_dir = BASE_DIR / "templates"
templates = Jinja2Templates(directory=str(templates_dir))

# Mount static files
static_dir = BASE_DIR / "static"
app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

# Import configuration
try:
    from app.config import config
    logger.info("Configuration loaded successfully")
except ImportError as e:
    logger.warning(f"Could not load config: {e}")
    # Create simple config
    class SimpleConfig:
        app_name = "Library Support AI"
        app_version = "1.0.0"
        base_dir = BASE_DIR
        pdfs_dir = BASE_DIR / "pdfs"
        vector_store_path = BASE_DIR / "vector_store"
        templates_dir = templates_dir
        chat_model = "qwen:0.5b"
        embedding_model = "all-minilm:latest"
        ollama_base_url = "http://localhost:11434"
    config = SimpleConfig()

# Create required directories
Path(config.pdfs_dir).mkdir(exist_ok=True)
Path(config.vector_store_path).mkdir(exist_ok=True)

# Import API routers
try:
    from app.api.chat import router as chat_router
    from app.api.files import router as files_router
    from app.api.system import router as system_router
    from app.api.tasks import router as tasks_router
    
    app.include_router(chat_router, prefix="/api/chat", tags=["chat"])
    app.include_router(files_router, prefix="/api/files", tags=["files"])
    app.include_router(system_router, tags=["system"])
    app.include_router(tasks_router, prefix="/api/tasks", tags=["tasks"])
    
    logger.info("API routers loaded successfully")
except ImportError as e:
    logger.warning(f"Could not load API routers: {e}")

# =================== TEMPLATE ROUTES ===================

@app.get("/", response_class=HTMLResponse)
async def root(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/chat", response_class=HTMLResponse)
async def chat_page(request: Request):
    return templates.TemplateResponse("chat.html", {"request": request})

@app.get("/files", response_class=HTMLResponse)
async def files_page(request: Request):
    """Serve files page with minimal data - JS will load the rest"""
    return templates.TemplateResponse(
        "files.html",
        {
            "request": request,
            "current_model": getattr(config, 'chat_model', 'qwen:0.5b'),
            "embedding_model": getattr(config, 'embedding_model', 'all-minilm:latest')
        }
    )

# =================== FRONTEND COMPATIBILITY ENDPOINTS ===================

@app.post("/upload")
async def upload_files_frontend(files: list[UploadFile] = File(...)):
    """Handle file upload from frontend"""
    uploaded = []
    pdfs_dir = Path(config.pdfs_dir)
    pdfs_dir.mkdir(exist_ok=True)
    
    for file in files:
        if file.filename.lower().endswith('.pdf'):
            path = pdfs_dir / file.filename
            with open(path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
            uploaded.append({"name": file.filename})
    
    return JSONResponse({
        "success": True,
        "uploaded": uploaded,
        "message": f"Uploaded {len(uploaded)} files"
    })

@app.get("/download/{filename}")
async def download_file_frontend(filename: str):
    """Download a file"""
    path = Path(config.pdfs_dir) / filename
    if path.exists() and path.is_file():
        return FileResponse(
            path=path,
            filename=filename,
            media_type='application/pdf'
        )
    return JSONResponse({"success": False, "message": "File not found"}, status_code=404)

@app.delete("/files/{filename}")
async def delete_file_frontend(filename: str):
    """Delete a file"""
    path = Path(config.pdfs_dir) / filename
    if path.exists():
        os.remove(path)
        return JSONResponse({"success": True, "message": f"Deleted {filename}"})
    return JSONResponse({"success": False, "message": "File not found"}, status_code=404)

@app.delete("/clear-all-files")
async def clear_all_files_frontend():
    """Clear all files"""
    pdfs_dir = Path(config.pdfs_dir)
    deleted_count = 0
    
    if pdfs_dir.exists():
        for f in os.listdir(pdfs_dir):
            if f.endswith(".pdf"):
                os.remove(pdfs_dir / f)
                deleted_count += 1
    
    return JSONResponse({
        "success": True,
        "message": f"Cleared {deleted_count} files",
        "deleted_count": deleted_count
    })

@app.post("/ingest")
async def ingest_frontend():
    """Process documents"""
    try:
        import subprocess
        import sys
        
        ingest_script = BASE_DIR / "ingest.py"
        if not ingest_script.exists():
            return JSONResponse({
                "success": False,
                "message": "Ingestion script not found"
            }, status_code=500)
        
        result = subprocess.run(
            [sys.executable, str(ingest_script)],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode == 0:
            return JSONResponse({
                "success": True,
                "message": "Documents processed successfully"
            })
        else:
            return JSONResponse({
                "success": False,
                "message": f"Processing failed: {result.stderr}"
            }, status_code=500)
            
    except Exception as e:
        return JSONResponse({
            "success": False,
            "message": f"Error: {str(e)}"
        }, status_code=500)

# =================== SYSTEM API ENDPOINTS ===================

@app.get("/api/engine-status")
async def engine_status():
    """Get AI engine status for frontend"""
    try:
        # Check if vector store exists
        vector_store_ready = False
        vector_store_path = Path(config.vector_store_path) / "vector_index.bin"
        if vector_store_path.exists():
            vector_store_ready = True
        
        # Check Ollama connection
        ollama_connected = False
        try:
            import requests
            response = requests.get(f"{config.ollama_base_url}/api/tags", timeout=3)
            ollama_connected = response.status_code == 200
        except:
            pass
        
        return {
            "chatModel": config.chat_model,
            "embeddingModel": config.embedding_model,
            "vectorStore": "Ready" if vector_store_ready else "Not ready",
            "ollamaStatus": "Connected" if ollama_connected else "Disconnected"
        }
        
    except Exception as e:
        logger.error(f"Error in engine-status: {e}")
        return {
            "chatModel": "Unknown",
            "embeddingModel": "Unknown",
            "vectorStore": "Error checking",
            "ollamaStatus": "Error checking"
        }

@app.get("/api/system/status")
async def system_status_frontend():
    """Get system status for frontend"""
    try:
        # Try to get from system module
        from app.api.system import system_status
        return await system_status()
    except ImportError:
        # Fallback implementation
        import psutil
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        cpu_percent = psutil.cpu_percent(interval=0.1)
        
        return {
            "cpu": {
                "percent": cpu_percent,
                "cores": psutil.cpu_count(),
                "load_average": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else [0, 0, 0]
            },
            "memory": {
                "total_gb": round(memory.total / 1024**3, 2),
                "used_gb": round(memory.used / 1024**3, 2),
                "percent": memory.percent
            },
            "disk": {
                "total_gb": round(disk.total / 1024**3, 2),
                "used_gb": round(disk.used / 1024**3, 2),
                "percent": disk.percent
            }
        }

@app.get("/api/config")
async def get_config_frontend():
    """Get configuration for frontend"""
    try:
        from app.api.system import get_configuration
        return await get_configuration()
    except ImportError:
        return {
            "current": {
                "chat_model": config.chat_model,
                "embedding_model": config.embedding_model,
                "ollama_base_url": config.ollama_base_url
            },
            "available_models": {
                "chat_models": [config.chat_model, "llama2:7b", "mistral:7b"],
                "embedding_models": [config.embedding_model, "nomic-embed-text:latest"]
            }
        }

@app.put("/api/config/model")
async def update_model_frontend(data: dict):
    """Update model configuration"""
    try:
        from app.api.system import update_model
        return await update_model(data)
    except ImportError:
        return JSONResponse({
            "success": False,
            "error": "Model update not available"
        }, status_code=501)

# =================== ERROR HANDLING ===================

@app.exception_handler(404)
async def not_found_exception_handler(request: Request, exc):
    if request.url.path.startswith('/api/'):
        return JSONResponse(status_code=404, content={"detail": "API endpoint not found"})
    return templates.TemplateResponse("index.html", {"request": request})

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
